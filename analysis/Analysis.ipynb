{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities and analysis setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict to map node ID to node address\n",
    "node_map = {\n",
    "    '1': 'planetlab2.citadel.edu',\n",
    "    '2': 'planetlab2.c3sl.ufpr.br',\n",
    "    '3': 'planetlab6.goto.info.waseda.ac.jp',\n",
    "    '4': 'pl-dccd-01.cua.uam.mx',\n",
    "    '5': 'planetlab3.rutgers.edu',\n",
    "    '6': 'planetlab2.ie.cuhk.edu.hk',\n",
    "    '7': 'planetlab1.temple.edu',\n",
    "    '8': 'planetlab1.rutgers.edu'\n",
    "}\n",
    "\n",
    "node_loc = {\n",
    "    '1': 'US (Citadel)',\n",
    "    '2': 'Brazil',\n",
    "    '3': 'Japan',\n",
    "    '4': 'Mexico',\n",
    "    '5': 'US (Rutgers 3)',\n",
    "    '6': 'Hong Kong',\n",
    "    '7': 'US (Temple)',\n",
    "    '8': 'US (Rutgers 1)'\n",
    "}\n",
    "\n",
    "node_pairs = {\n",
    "    '1': '1-2 & 2-1'\n",
    "}\n",
    "\n",
    "# dict to map each node's to its respective timezone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the current working directory to the project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/jlahut/UAlbany/comp-comm-networks/final-project/project/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data files\n",
    "Data files have the following format `<type>_<src>-<dest>_<Y-M-D>_<H-M-S>`  \n",
    "*The timestamps in the file names are local to the node in which it came from*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read file: traceroute_-_2019-11-21_01-36-28.txt\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for filename in os.listdir(\"data/\"):\n",
    "    try:\n",
    "        items = filename.split('_')\n",
    "\n",
    "        measure = items[0]\n",
    "        src, dest = items[1].split('-')\n",
    "\n",
    "        date = items[2]\n",
    "        time = items[3].split('.')[0]\n",
    "\n",
    "        timestamp = datetime.strptime(f'{date} {time}', '%Y-%m-%d %H-%M-%S')\n",
    "        content = ''\n",
    "\n",
    "        with open(os.path.join('data', filename), 'r') as file:\n",
    "            content = file.read()\n",
    "            \n",
    "        if (src == '1' and dest == '2') or (src == '2' and dest == '1'):\n",
    "            pair = '1-2 & 2-1'\n",
    "        elif (src == '3' and dest == '5') or (src == '5' and dest == '3'):\n",
    "            pair = '3-5 & 5-3'\n",
    "        elif (src == '4' and dest == '7') or (src == '7' and dest == '4'):\n",
    "            pair = '4-7 & 7-4'\n",
    "        elif (src == '6' and dest == '8') or (src == '8' and dest == '6'):\n",
    "            pair = '6-8 & 8-6'\n",
    "        elif (src == '1' and dest == '5') or (src == '5' and dest == '1'):\n",
    "            pair = '1-5 & 5-1'\n",
    "        else:\n",
    "            pair = 'Error'\n",
    "\n",
    "        data.append([src, dest, timestamp, measure, node_map[src], node_map[dest], content, filename, pair])\n",
    "    except:\n",
    "        print(f'Could not read file: {filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 'master' dataframe to hold all raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns = ['src_id', 'dest_id', 'time', 'measure', 'src_name', 'dest_name', 'raw_data', 'filename', 'pair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ping and Traceroute functions to be applied accross the dataframe\n",
    "- Used mainly for file parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example format\n",
    "# rtt min/avg/max/mdev = 68.244/68.337/68.498/0.129 ms or\n",
    "# rtt min/avg/max/mdev = 68.244/68.337/68.498/0.129 ms, pipe n\n",
    "# 20 packets transmitted, 20 received, 0% packet loss, time 19029ms\n",
    "def analyze_ping(data):\n",
    "    try:\n",
    "        # --- parse out statistics ---\n",
    "        # second to last line will always be calculated values\n",
    "        # split on '=' sign, then strip all spaces, remove units, and finally split on '/'\n",
    "        # giving the values we need\n",
    "        metrics = data['raw_data'].split('\\n')[-2].split('=')[1].strip().replace(' ms', '').split(',')[0].split('/')\n",
    "        data['min_ping_time'], data['avg_ping_time'], data['max_ping_time'], data['sd_ping_time'] = \\\n",
    "            float(metrics[0]), float(metrics[1]), float(metrics[2]), float(metrics[3])\n",
    "        \n",
    "        # --- parse out packet loss ---\n",
    "        # third to last line will always be the line with packet loss\n",
    "        data['packet_loss'] = float(data['raw_data'].split('\\n')[-3].split(',')[2].split(' ')[1].replace('%', ''))\n",
    "    except Exception as e:\n",
    "        print(f\"No calculated data for: {data['filename']}\")\n",
    "    return data\n",
    "\n",
    "def analyze_traceroute(data):\n",
    "    # TODO\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No calculated data for: ping_5-3_2019-11-28_20-26-34.txt\n",
      "No calculated data for: ping_7-4_2019-11-27_03-21-14.txt\n",
      "No calculated data for: ping_8-6_2019-11-25_18-34-59.txt\n",
      "No calculated data for: ping_5-3_2019-11-25_18-09-07.txt\n",
      "No calculated data for: ping_2-1_2019-11-22_20-02-21.txt\n"
     ]
    }
   ],
   "source": [
    "df = df[df['measure'] == 'ping'].apply(analyze_ping, axis = 1)\n",
    "# df = df[df['measure'] == 'traceroute'].apply(analyze_traceroute, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting average ping times for nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for title, group in df[df['measure'] == 'ping'].groupby(['src_id', 'dest_id']):\n",
    "    ax = group.plot(x = 'time', y = 'avg_ping_time', title = f'{node_loc[title[0]]} to {node_loc[title[1]]}')\n",
    "    ax.legend(['Average Ping Time'])\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Time (ms)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate CDF for packet loss and latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create CDF latency and CDF packet loss plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# first group by each src, desc pair\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "legend = []\n",
    "for title, group in df[df['measure'] == 'ping'].groupby(['pair']):\n",
    "    \n",
    "    # then group by the avg_ping_time\n",
    "    stats_df = group.groupby('avg_ping_time')['avg_ping_time'].agg('count').pipe(pd.DataFrame).rename(\n",
    "        columns = {'avg_ping_time': 'frequency'})\n",
    "    \n",
    "    # probability that the current time occurs\n",
    "    stats_df['pdf'] = stats_df['frequency'] / sum(stats_df['frequency'])\n",
    "    # cumulative probability\n",
    "    stats_df['cdf'] = stats_df['pdf'].cumsum()\n",
    "    stats_df = stats_df.reset_index()\n",
    "    \n",
    "    # add the max value to each plot so that the CDF lines continue to end\n",
    "    plt.plot(stats_df['avg_ping_time'].tolist()+[df['avg_ping_time'].max()],stats_df['cdf'].tolist()+[1])\n",
    "    \n",
    "    if '1-2' in title:\n",
    "        legend.append('Nodes 1 and 2')\n",
    "    elif '1-5' in title:\n",
    "        legend.append('Nodes 1 and 5')\n",
    "    elif '3-5' in title:\n",
    "        legend.append('Nodes 3 and 5')\n",
    "    elif '4-7' in title:\n",
    "        legend.append('Nodes 4 and 7')\n",
    "    elif '6-8' in title:\n",
    "        legend.append('Nodes 6 and 8')\n",
    "    ax.legend(legend)\n",
    "    ax.set_title('Nodal Latency CDF')\n",
    "    ax.set_xlabel('Average Ping Time (ms)')\n",
    "    ax.set_ylabel('Probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first group by each src, desc pair\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "legend = []\n",
    "for title, group in df[df['measure'] == 'ping'].groupby(['pair']):\n",
    "    \n",
    "    # then group by the avg_ping_time\n",
    "    stats_df = group.groupby('packet_loss')['packet_loss'].agg('count').pipe(pd.DataFrame).rename(\n",
    "        columns = {'packet_loss': 'frequency'})\n",
    "    \n",
    "    # probability that the current time occurs\n",
    "    stats_df['pdf'] = stats_df['frequency'] / sum(stats_df['frequency'])\n",
    "    # cumulative probability\n",
    "    stats_df['cdf'] = stats_df['pdf'].cumsum()\n",
    "    stats_df = stats_df.reset_index()\n",
    "    \n",
    "    # add the max value to each plot so that the CDF lines continue to end\n",
    "    plt.plot(stats_df['packet_loss'].tolist()+[df['packet_loss'].max()],stats_df['cdf'].tolist()+[1])\n",
    "    \n",
    "    if '1-2' in title:\n",
    "        legend.append('Nodes 1 and 2')\n",
    "    elif '1-5' in title:\n",
    "        legend.append('Nodes 1 and 5')\n",
    "    elif '3-5' in title:\n",
    "        legend.append('Nodes 3 and 5')\n",
    "    elif '4-7' in title:\n",
    "        legend.append('Nodes 4 and 7')\n",
    "    elif '6-8' in title:\n",
    "        legend.append('Nodes 6 and 8')\n",
    "    ax.legend(legend)\n",
    "    ax.set_title('Nodal Packet Loss CDF')\n",
    "    ax.set_xlabel('Packet Loss (%)')\n",
    "    ax.set_ylabel('Probability')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
